pad_to = 54  # maximum number of tokens in a sentence

emb_size = 128
hidden_size = 512
num_layers = 2
dropout = 0.1

batch_size = 1400
learning_rate = 1e-3
